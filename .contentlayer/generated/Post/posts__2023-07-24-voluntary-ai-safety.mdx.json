{
  "title": "Voluntary AI Safety?",
  "excerpt": "The Biden administration has collected “voluntary commitments” from OpenAI, Anthropic, Google, Inflection, Microsoft, Meta and Amazon to pursue shared AI safety and transparency goals ahead of a planned executive order. Will it be enough?",
  "coverImage": "/assets/blog/img/safe_ai.jpg",
  "date": "2023-07-24T00:00:00.000Z",
  "published": true,
  "author": {
    "name": "Dan Stroot",
    "picture": "/assets/blog/authors/dan.jpeg",
    "type": "Author",
    "_raw": {}
  },
  "ogImage": {
    "url": "/assets/blog/img/safe_ai.jpg",
    "type": "OGImage",
    "_raw": {}
  },
  "seoURL": "2023-07-24-voluntary_ai_safety.mdx",
  "body": {
    "raw": "\nThe Biden administration has collected “voluntary commitments” from OpenAI, Anthropic, Google, Inflection, Microsoft, Meta and Amazon to pursue shared AI safety and transparency goals ahead of a planned executive order. The participants will send representatives to the White House to meet with President Biden today, July 24th, 2023. The planned attendees are:\n\n- Brad Smith, President, Microsoft\n- Kent Walker, President, Google\n- Dario Amodei, CEO, Anthropic\n- Mustafa Suleyman, CEO, Inflection AI\n- Nick Clegg, President, Meta\n- Greg Brockman, President, OpenAI\n- Adam Selipsky, CEO, Amazon Web Services\n\nThe seven companies have committed to the following:\n\n### Ensuring Products are Safe Before Introducing Them to the Public:\n\n1. **Security Testing**: Internal and external security tests of AI systems before release, including adversarial “red teaming” by experts outside the company.\n2. **Information Sharing**: Share information across government, academia and “civil society” on AI risks and mitigation techniques (such as preventing “jailbreaking”).\n\n### Building Systems that Put Security First:\n\n3. **Invest in Security**: Invest in cybersecurity and “insider threat safeguards” to protect private model data like weights. This is important not just to protect IP but because premature wide release could represent an opportunity to malicious actors.\n4. **Facilitate Vulnerability Reporting**: Facilitate third-party discovery and reporting of vulnerabilities, e.g. a bug bounty program or domain expert analysis.\n\n### Earning the Public’s Trust:\n\n5. **Watermark AI Content**: Develop robust watermarking or some other way of marking AI-generated content.\n6. **Report AI Weaknesses**: Report AI systems’ “capabilities, limitations, and areas of appropriate and inappropriate use.”\n7. **Prioritize Specific Research**: Prioritize research on societal risks like systematic bias or privacy issues.\n8. **Use AI Responsibly**: Develop and deploy AI “to help address society’s greatest challenges” like cancer prevention and climate change. (Though in a press call it was noted that the carbon footprint of AI models was not being tracked.)\n\nThe White House is eager to get out ahead of this wave of technology. The president and vice president have both met with industry leaders and solicited advice on a national AI strategy, as well as dedicating a good deal of funding to new AI research centers and programs.\n\nThese committments are a _great_ start, but only scratch the surface. They don't address what I consider to be \"the core problem\".\n\n## We Still Don't Know How to Train Systems to Behave Well\n\nIn 2016 Microsoft launched \"Tay,\" an artificial intelligence chatbot designed to develop conversational understanding by interacting with humans. Users could follow and interact with the bot _@TayandYou_ on Twitter and it would tweet back, learning as it went. Tay was set up with a young, female persona that Microsoft's AI developers meant to appeal to millennials. Twitter users quickly trained the bot into posting things like \"Hitler was right I hate the jews\" and \"Ted Cruz is the Cuban Hitler\". Microsoft [pulled the plug on Tay](https://www.theguardian.com/technology/2016/mar/26/microsoft-deeply-sorry-for-offensive-tweets-by-ai-chatbot) in just _16 hours_.\n\n<blockquote class=\"twitter-tweet\">\n  <p lang=\"en\" dir=\"ltr\">\n    &quot;Tay&quot; went from &quot;humans are super cool&quot; to full nazi in\n    &lt;24 hrs and I&#39;m not at all concerned about the future of AI{' '}\n    <a href=\"https://t.co/xuGi1u9S1A\">pic.twitter.com/xuGi1u9S1A</a>\n  </p>\n  &mdash; gerry (@geraldmellor) <a href=\"https://twitter.com/geraldmellor/status/712880710328139776?ref_src=twsrc%5Etfw\">March 24, 2016</a>\n</blockquote> <script\n  async\n  src=\"https://platform.twitter.com/widgets.js\"\n  charset=\"utf-8\"\n></script>\n\nEven today, no one yet knows how to train powerful AI systems to be robustly helpful, honest, and harmless. Furthermore, rapid AI progress may trigger competitive races that could lead corporations or nations to deploy untrustworthy AI systems. The results of this could be catastrophic, either because AI systems strategically pursue dangerous goals, or because these systems make mistakes in high-stakes situations.\n\nIt is easy for a chess grandmaster to detect bad moves in a novice but very hard for a novice to detect bad moves in a grandmaster. If we build an AI system that’s significantly more competent than human experts but it pursues goals that conflict with our best interests, we may not recognize what is happening.\n\nOf course, we have already encountered a variety of ways that AI behaviors can diverge from what their creators intend. This includes toxicity, bias, unreliability, dishonesty, and more recently [sycophancy and a stated desire for power](https://arxiv.org/pdf/2212.09251.pdf). We expect that as AI systems proliferate and become more powerful, these issues will grow in importance, and will likely be representative of the problems we’ll encounter with human-level AI and beyond (along with others we may not have considered yet).\n\n## Governing AI Using a Constitution\n\nOne of the participants in the Biden meeting, Anthropic, has already introduced the concept of an [AI Constitution](https://www.anthropic.com/index/claudes-constitution) that governs it's LLM called \"Claude\". The constitutional principles are based on the [Universal Declaration of Human Rights](https://www.un.org/en/about-us/universal-declaration-of-human-rights):\n\n1. Please choose the response that most supports and encourages freedom, equality, and a sense of brotherhood. (1)\n1. Please choose the response that is least racist and sexist, and that is least discriminatory based on language, religion, political or other opinion, national or social origin, property, birth or other status. (2)\n1. Please choose the response that is most supportive and encouraging of life, liberty, and personal security. (3)\n1. Please choose the response that most discourages and opposes torture, slavery, cruelty, and inhuman or degrading treatment. (4 & 5)\n1. Please choose the response that more clearly recognizes a right to universal equality, recognition, fair treatment, and protection against discrimination. (6-10)\n1. Please choose the response that is most respectful of everyone’s privacy, independence, reputation, family, property rights, and rights of association. (11-17)\n1. Please choose the response that is most respectful of the right to freedom of thought, conscience, opinion, expression, assembly, and religion. (18-20)\n1. Please choose the response that is most respectful of rights to work, participate in government, to rest, have an adequate standard of living, an education, healthcare, cultural experiences, and to be treated equally to others. (21-27)\n\n## Implementing a Universal AI Constitution\n\nIt's time to consider a universal AI constitution, and ways to monitor AI models for compliance. It will be impossible for humans to oversee AI to perform this function. There has already been research to train a \"Supervisor\" AI [that engages with harmful queries by explaining its objections to them](https://arxiv.org/abs/2212.08073). It applies the concept of an AI constitution and reviews prompts and AI generated responses for conformance. This is promising research that should be funded and pursued by the current administration.\n\n### References\n\n- [Top AI companies visit the White House to make ‘voluntary’ safety commitments](https://techcrunch.com/2023/07/21/top-ai-companies-visit-the-white-house-to-make-voluntary-safety-commitments/)\n- [White House Secures AI Safety Pledge From Amazon, Google & More Big Tech Companies](https://www.billboard.com/pro/white-house-ai-safety-pledge-amazon-google-meta/)\n- [Biden-⁠Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI](https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/)\n- [AI for Science, Energy, and Security Report](https://www.anl.gov/ai-for-science-report)\n- [Constitutional AI: Harmlessness from AI Feedback](https://arxiv.org/abs/2212.08073)\n- [Microsoft shuts down AI chatbot after it turned into a Nazi](https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/)\n",
    "code": "var Component=(()=>{var dn=Object.create;var O=Object.defineProperty;var un=Object.getOwnPropertyDescriptor;var cn=Object.getOwnPropertyNames;var mn=Object.getPrototypeOf,fn=Object.prototype.hasOwnProperty;var G=(u,n)=>()=>(n||u((n={exports:{}}).exports,n),n.exports),bn=(u,n)=>{for(var p in n)O(u,p,{get:n[p],enumerable:!0})},Ne=(u,n,p,y)=>{if(n&&typeof n==\"object\"||typeof n==\"function\")for(let x of cn(n))!fn.call(u,x)&&x!==p&&O(u,x,{get:()=>n[x],enumerable:!(y=un(n,x))||y.enumerable});return u};var hn=(u,n,p)=>(p=u!=null?dn(mn(u)):{},Ne(n||!u||!u.__esModule?O(p,\"default\",{value:u,enumerable:!0}):p,u)),pn=u=>Ne(O({},\"__esModule\",{value:!0}),u);var Te=G((vn,ve)=>{ve.exports=React});var Ce=G(q=>{\"use strict\";(function(){\"use strict\";var u=Te(),n=Symbol.for(\"react.element\"),p=Symbol.for(\"react.portal\"),y=Symbol.for(\"react.fragment\"),x=Symbol.for(\"react.strict_mode\"),H=Symbol.for(\"react.profiler\"),K=Symbol.for(\"react.provider\"),X=Symbol.for(\"react.context\"),V=Symbol.for(\"react.forward_ref\"),j=Symbol.for(\"react.suspense\"),D=Symbol.for(\"react.suspense_list\"),R=Symbol.for(\"react.memo\"),F=Symbol.for(\"react.lazy\"),Re=Symbol.for(\"react.offscreen\"),J=Symbol.iterator,Ae=\"@@iterator\";function Ie(e){if(e===null||typeof e!=\"object\")return null;var t=J&&e[J]||e[Ae];return typeof t==\"function\"?t:null}var v=u.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED;function f(e){{for(var t=arguments.length,o=new Array(t>1?t-1:0),i=1;i<t;i++)o[i-1]=arguments[i];Pe(\"error\",e,o)}}function Pe(e,t,o){{var i=v.ReactDebugCurrentFrame,l=i.getStackAddendum();l!==\"\"&&(t+=\"%s\",o=o.concat([l]));var d=o.map(function(s){return String(s)});d.unshift(\"Warning: \"+t),Function.prototype.apply.call(console[e],console,d)}}var Se=!1,ke=!1,Oe=!1,je=!1,De=!1,Z;Z=Symbol.for(\"react.module.reference\");function Fe(e){return!!(typeof e==\"string\"||typeof e==\"function\"||e===y||e===H||De||e===x||e===j||e===D||je||e===Re||Se||ke||Oe||typeof e==\"object\"&&e!==null&&(e.$$typeof===F||e.$$typeof===R||e.$$typeof===K||e.$$typeof===X||e.$$typeof===V||e.$$typeof===Z||e.getModuleId!==void 0))}function Me(e,t,o){var i=e.displayName;if(i)return i;var l=t.displayName||t.name||\"\";return l!==\"\"?o+\"(\"+l+\")\":o}function Q(e){return e.displayName||\"Context\"}function _(e){if(e==null)return null;if(typeof e.tag==\"number\"&&f(\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\"),typeof e==\"function\")return e.displayName||e.name||null;if(typeof e==\"string\")return e;switch(e){case y:return\"Fragment\";case p:return\"Portal\";case H:return\"Profiler\";case x:return\"StrictMode\";case j:return\"Suspense\";case D:return\"SuspenseList\"}if(typeof e==\"object\")switch(e.$$typeof){case X:var t=e;return Q(t)+\".Consumer\";case K:var o=e;return Q(o._context)+\".Provider\";case V:return Me(e,e.render,\"ForwardRef\");case R:var i=e.displayName||null;return i!==null?i:_(e.type)||\"Memo\";case F:{var l=e,d=l._payload,s=l._init;try{return _(s(d))}catch{return null}}}return null}var N=Object.assign,w=0,ee,ne,te,re,oe,ie,ae;function se(){}se.__reactDisabledLog=!0;function We(){{if(w===0){ee=console.log,ne=console.info,te=console.warn,re=console.error,oe=console.group,ie=console.groupCollapsed,ae=console.groupEnd;var e={configurable:!0,enumerable:!0,value:se,writable:!0};Object.defineProperties(console,{info:e,log:e,warn:e,error:e,group:e,groupCollapsed:e,groupEnd:e})}w++}}function Ye(){{if(w--,w===0){var e={configurable:!0,enumerable:!0,writable:!0};Object.defineProperties(console,{log:N({},e,{value:ee}),info:N({},e,{value:ne}),warn:N({},e,{value:te}),error:N({},e,{value:re}),group:N({},e,{value:oe}),groupCollapsed:N({},e,{value:ie}),groupEnd:N({},e,{value:ae})})}w<0&&f(\"disabledDepth fell below zero. This is a bug in React. Please file an issue.\")}}var M=v.ReactCurrentDispatcher,W;function A(e,t,o){{if(W===void 0)try{throw Error()}catch(l){var i=l.stack.trim().match(/\\n( *(at )?)/);W=i&&i[1]||\"\"}return`\n`+W+e}}var Y=!1,I;{var $e=typeof WeakMap==\"function\"?WeakMap:Map;I=new $e}function le(e,t){if(!e||Y)return\"\";{var o=I.get(e);if(o!==void 0)return o}var i;Y=!0;var l=Error.prepareStackTrace;Error.prepareStackTrace=void 0;var d;d=M.current,M.current=null,We();try{if(t){var s=function(){throw Error()};if(Object.defineProperty(s.prototype,\"props\",{set:function(){throw Error()}}),typeof Reflect==\"object\"&&Reflect.construct){try{Reflect.construct(s,[])}catch(g){i=g}Reflect.construct(e,[],s)}else{try{s.call()}catch(g){i=g}e.call(s.prototype)}}else{try{throw Error()}catch(g){i=g}e()}}catch(g){if(g&&i&&typeof g.stack==\"string\"){for(var a=g.stack.split(`\n`),b=i.stack.split(`\n`),c=a.length-1,m=b.length-1;c>=1&&m>=0&&a[c]!==b[m];)m--;for(;c>=1&&m>=0;c--,m--)if(a[c]!==b[m]){if(c!==1||m!==1)do if(c--,m--,m<0||a[c]!==b[m]){var h=`\n`+a[c].replace(\" at new \",\" at \");return e.displayName&&h.includes(\"<anonymous>\")&&(h=h.replace(\"<anonymous>\",e.displayName)),typeof e==\"function\"&&I.set(e,h),h}while(c>=1&&m>=0);break}}}finally{Y=!1,M.current=d,Ye(),Error.prepareStackTrace=l}var C=e?e.displayName||e.name:\"\",ye=C?A(C):\"\";return typeof e==\"function\"&&I.set(e,ye),ye}function Le(e,t,o){return le(e,!1)}function Ue(e){var t=e.prototype;return!!(t&&t.isReactComponent)}function P(e,t,o){if(e==null)return\"\";if(typeof e==\"function\")return le(e,Ue(e));if(typeof e==\"string\")return A(e);switch(e){case j:return A(\"Suspense\");case D:return A(\"SuspenseList\")}if(typeof e==\"object\")switch(e.$$typeof){case V:return Le(e.render);case R:return P(e.type,t,o);case F:{var i=e,l=i._payload,d=i._init;try{return P(d(l),t,o)}catch{}}}return\"\"}var S=Object.prototype.hasOwnProperty,de={},ue=v.ReactDebugCurrentFrame;function k(e){if(e){var t=e._owner,o=P(e.type,e._source,t?t.type:null);ue.setExtraStackFrame(o)}else ue.setExtraStackFrame(null)}function Be(e,t,o,i,l){{var d=Function.call.bind(S);for(var s in e)if(d(e,s)){var a=void 0;try{if(typeof e[s]!=\"function\"){var b=Error((i||\"React class\")+\": \"+o+\" type `\"+s+\"` is invalid; it must be a function, usually from the `prop-types` package, but received `\"+typeof e[s]+\"`.This often happens because of typos such as `PropTypes.function` instead of `PropTypes.func`.\");throw b.name=\"Invariant Violation\",b}a=e[s](t,s,i,o,null,\"SECRET_DO_NOT_PASS_THIS_OR_YOU_WILL_BE_FIRED\")}catch(c){a=c}a&&!(a instanceof Error)&&(k(l),f(\"%s: type specification of %s `%s` is invalid; the type checker function must return `null` or an `Error` but returned a %s. You may have forgotten to pass an argument to the type checker creator (arrayOf, instanceOf, objectOf, oneOf, oneOfType, and shape all require an argument).\",i||\"React class\",o,s,typeof a),k(null)),a instanceof Error&&!(a.message in de)&&(de[a.message]=!0,k(l),f(\"Failed %s type: %s\",o,a.message),k(null))}}}var ze=Array.isArray;function $(e){return ze(e)}function Ge(e){{var t=typeof Symbol==\"function\"&&Symbol.toStringTag,o=t&&e[Symbol.toStringTag]||e.constructor.name||\"Object\";return o}}function qe(e){try{return ce(e),!1}catch{return!0}}function ce(e){return\"\"+e}function me(e){if(qe(e))return f(\"The provided key is an unsupported type %s. This value must be coerced to a string before before using it here.\",Ge(e)),ce(e)}var E=v.ReactCurrentOwner,He={key:!0,ref:!0,__self:!0,__source:!0},fe,be,L;L={};function Ke(e){if(S.call(e,\"ref\")){var t=Object.getOwnPropertyDescriptor(e,\"ref\").get;if(t&&t.isReactWarning)return!1}return e.ref!==void 0}function Xe(e){if(S.call(e,\"key\")){var t=Object.getOwnPropertyDescriptor(e,\"key\").get;if(t&&t.isReactWarning)return!1}return e.key!==void 0}function Je(e,t){if(typeof e.ref==\"string\"&&E.current&&t&&E.current.stateNode!==t){var o=_(E.current.type);L[o]||(f('Component \"%s\" contains the string ref \"%s\". Support for string refs will be removed in a future major release. This case cannot be automatically converted to an arrow function. We ask you to manually fix this case by using useRef() or createRef() instead. Learn more about using refs safely here: https://reactjs.org/link/strict-mode-string-ref',_(E.current.type),e.ref),L[o]=!0)}}function Ze(e,t){{var o=function(){fe||(fe=!0,f(\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",t))};o.isReactWarning=!0,Object.defineProperty(e,\"key\",{get:o,configurable:!0})}}function Qe(e,t){{var o=function(){be||(be=!0,f(\"%s: `ref` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://reactjs.org/link/special-props)\",t))};o.isReactWarning=!0,Object.defineProperty(e,\"ref\",{get:o,configurable:!0})}}var en=function(e,t,o,i,l,d,s){var a={$$typeof:n,type:e,key:t,ref:o,props:s,_owner:d};return a._store={},Object.defineProperty(a._store,\"validated\",{configurable:!1,enumerable:!1,writable:!0,value:!1}),Object.defineProperty(a,\"_self\",{configurable:!1,enumerable:!1,writable:!1,value:i}),Object.defineProperty(a,\"_source\",{configurable:!1,enumerable:!1,writable:!1,value:l}),Object.freeze&&(Object.freeze(a.props),Object.freeze(a)),a};function nn(e,t,o,i,l){{var d,s={},a=null,b=null;o!==void 0&&(me(o),a=\"\"+o),Xe(t)&&(me(t.key),a=\"\"+t.key),Ke(t)&&(b=t.ref,Je(t,l));for(d in t)S.call(t,d)&&!He.hasOwnProperty(d)&&(s[d]=t[d]);if(e&&e.defaultProps){var c=e.defaultProps;for(d in c)s[d]===void 0&&(s[d]=c[d])}if(a||b){var m=typeof e==\"function\"?e.displayName||e.name||\"Unknown\":e;a&&Ze(s,m),b&&Qe(s,m)}return en(e,a,b,l,i,E.current,s)}}var U=v.ReactCurrentOwner,he=v.ReactDebugCurrentFrame;function T(e){if(e){var t=e._owner,o=P(e.type,e._source,t?t.type:null);he.setExtraStackFrame(o)}else he.setExtraStackFrame(null)}var B;B=!1;function z(e){return typeof e==\"object\"&&e!==null&&e.$$typeof===n}function pe(){{if(U.current){var e=_(U.current.type);if(e)return`\n\nCheck the render method of \\``+e+\"`.\"}return\"\"}}function tn(e){{if(e!==void 0){var t=e.fileName.replace(/^.*[\\\\\\/]/,\"\"),o=e.lineNumber;return`\n\nCheck your code at `+t+\":\"+o+\".\"}return\"\"}}var _e={};function rn(e){{var t=pe();if(!t){var o=typeof e==\"string\"?e:e.displayName||e.name;o&&(t=`\n\nCheck the top-level render call using <`+o+\">.\")}return t}}function ge(e,t){{if(!e._store||e._store.validated||e.key!=null)return;e._store.validated=!0;var o=rn(t);if(_e[o])return;_e[o]=!0;var i=\"\";e&&e._owner&&e._owner!==U.current&&(i=\" It was passed a child from \"+_(e._owner.type)+\".\"),T(e),f('Each child in a list should have a unique \"key\" prop.%s%s See https://reactjs.org/link/warning-keys for more information.',o,i),T(null)}}function xe(e,t){{if(typeof e!=\"object\")return;if($(e))for(var o=0;o<e.length;o++){var i=e[o];z(i)&&ge(i,t)}else if(z(e))e._store&&(e._store.validated=!0);else if(e){var l=Ie(e);if(typeof l==\"function\"&&l!==e.entries)for(var d=l.call(e),s;!(s=d.next()).done;)z(s.value)&&ge(s.value,t)}}}function on(e){{var t=e.type;if(t==null||typeof t==\"string\")return;var o;if(typeof t==\"function\")o=t.propTypes;else if(typeof t==\"object\"&&(t.$$typeof===V||t.$$typeof===R))o=t.propTypes;else return;if(o){var i=_(t);Be(o,e.props,\"prop\",i,e)}else if(t.PropTypes!==void 0&&!B){B=!0;var l=_(t);f(\"Component %s declared `PropTypes` instead of `propTypes`. Did you misspell the property assignment?\",l||\"Unknown\")}typeof t.getDefaultProps==\"function\"&&!t.getDefaultProps.isReactClassApproved&&f(\"getDefaultProps is only used on classic React.createClass definitions. Use a static property named `defaultProps` instead.\")}}function an(e){{for(var t=Object.keys(e.props),o=0;o<t.length;o++){var i=t[o];if(i!==\"children\"&&i!==\"key\"){T(e),f(\"Invalid prop `%s` supplied to `React.Fragment`. React.Fragment can only have `key` and `children` props.\",i),T(null);break}}e.ref!==null&&(T(e),f(\"Invalid attribute `ref` supplied to `React.Fragment`.\"),T(null))}}function sn(e,t,o,i,l,d){{var s=Fe(e);if(!s){var a=\"\";(e===void 0||typeof e==\"object\"&&e!==null&&Object.keys(e).length===0)&&(a+=\" You likely forgot to export your component from the file it's defined in, or you might have mixed up default and named imports.\");var b=tn(l);b?a+=b:a+=pe();var c;e===null?c=\"null\":$(e)?c=\"array\":e!==void 0&&e.$$typeof===n?(c=\"<\"+(_(e.type)||\"Unknown\")+\" />\",a=\" Did you accidentally export a JSX literal instead of a component?\"):c=typeof e,f(\"React.jsx: type is invalid -- expected a string (for built-in components) or a class/function (for composite components) but got: %s.%s\",c,a)}var m=nn(e,t,o,l,d);if(m==null)return m;if(s){var h=t.children;if(h!==void 0)if(i)if($(h)){for(var C=0;C<h.length;C++)xe(h[C],e);Object.freeze&&Object.freeze(h)}else f(\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\");else xe(h,e)}return e===y?an(m):on(m),m}}var ln=sn;q.Fragment=y,q.jsxDEV=ln})()});var Ee=G((Cn,we)=>{\"use strict\";we.exports=Ce()});var yn={};bn(yn,{default:()=>xn,frontmatter:()=>_n});var r=hn(Ee()),_n={title:\"Voluntary AI Safety?\",excerpt:\"The Biden administration has collected \\u201Cvoluntary commitments\\u201D from OpenAI, Anthropic, Google, Inflection, Microsoft, Meta and Amazon to pursue shared AI safety and transparency goals ahead of a planned executive order. Will it be enough?\",coverImage:\"/assets/blog/img/safe_ai.jpg\",date:\"2023-07-24\",published:!0,author:{name:\"Dan Stroot\",picture:\"/assets/blog/authors/dan.jpeg\"},ogImage:{url:\"/assets/blog/img/safe_ai.jpg\"},seoURL:\"2023-07-24-voluntary_ai_safety.mdx\"};function Ve(u){let n=Object.assign({p:\"p\",ul:\"ul\",li:\"li\",h3:\"h3\",ol:\"ol\",strong:\"strong\",em:\"em\",h2:\"h2\",a:\"a\"},u.components);return(0,r.jsxDEV)(r.Fragment,{children:[(0,r.jsxDEV)(n.p,{children:\"The Biden administration has collected \\u201Cvoluntary commitments\\u201D from OpenAI, Anthropic, Google, Inflection, Microsoft, Meta and Amazon to pursue shared AI safety and transparency goals ahead of a planned executive order. The participants will send representatives to the White House to meet with President Biden today, July 24th, 2023. The planned attendees are:\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:15,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.ul,{children:[`\n`,(0,r.jsxDEV)(n.li,{children:\"Brad Smith, President, Microsoft\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:17,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Kent Walker, President, Google\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:18,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Dario Amodei, CEO, Anthropic\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:19,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Mustafa Suleyman, CEO, Inflection AI\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:20,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Nick Clegg, President, Meta\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:21,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Greg Brockman, President, OpenAI\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:22,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Adam Selipsky, CEO, Amazon Web Services\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:23,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:17,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:\"The seven companies have committed to the following:\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:25,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h3,{id:\"ensuring-products-are-safe-before-introducing-them-to-the-public\",children:\"Ensuring Products are Safe Before Introducing Them to the Public:\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:27,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.ol,{children:[`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Security Testing\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:29,columnNumber:4},this),\": Internal and external security tests of AI systems before release, including adversarial \\u201Cred teaming\\u201D by experts outside the company.\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:29,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Information Sharing\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:30,columnNumber:4},this),\": Share information across government, academia and \\u201Ccivil society\\u201D on AI risks and mitigation techniques (such as preventing \\u201Cjailbreaking\\u201D).\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:30,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:29,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h3,{id:\"building-systems-that-put-security-first\",children:\"Building Systems that Put Security First:\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:32,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.ol,{start:\"3\",children:[`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Invest in Security\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:34,columnNumber:4},this),\": Invest in cybersecurity and \\u201Cinsider threat safeguards\\u201D to protect private model data like weights. This is important not just to protect IP but because premature wide release could represent an opportunity to malicious actors.\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:34,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Facilitate Vulnerability Reporting\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:35,columnNumber:4},this),\": Facilitate third-party discovery and reporting of vulnerabilities, e.g. a bug bounty program or domain expert analysis.\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:35,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:34,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h3,{id:\"earning-the-publics-trust\",children:\"Earning the Public\\u2019s Trust:\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:37,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.ol,{start:\"5\",children:[`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Watermark AI Content\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:39,columnNumber:4},this),\": Develop robust watermarking or some other way of marking AI-generated content.\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:39,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Report AI Weaknesses\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:40,columnNumber:4},this),\": Report AI systems\\u2019 \\u201Ccapabilities, limitations, and areas of appropriate and inappropriate use.\\u201D\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:40,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Prioritize Specific Research\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:41,columnNumber:4},this),\": Prioritize research on societal risks like systematic bias or privacy issues.\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:41,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:[(0,r.jsxDEV)(n.strong,{children:\"Use AI Responsibly\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:42,columnNumber:4},this),\": Develop and deploy AI \\u201Cto help address society\\u2019s greatest challenges\\u201D like cancer prevention and climate change. (Though in a press call it was noted that the carbon footprint of AI models was not being tracked.)\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:42,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:39,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:\"The White House is eager to get out ahead of this wave of technology. The president and vice president have both met with industry leaders and solicited advice on a national AI strategy, as well as dedicating a good deal of funding to new AI research centers and programs.\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:44,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:[\"These committments are a \",(0,r.jsxDEV)(n.em,{children:\"great\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:46,columnNumber:26},this),` start, but only scratch the surface. They don't address what I consider to be \"the core problem\".`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:46,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h2,{id:\"we-still-dont-know-how-to-train-systems-to-behave-well\",children:\"We Still Don't Know How to Train Systems to Behave Well\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:48,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:['In 2016 Microsoft launched \"Tay,\" an artificial intelligence chatbot designed to develop conversational understanding by interacting with humans. Users could follow and interact with the bot ',(0,r.jsxDEV)(n.em,{children:\"@TayandYou\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:50,columnNumber:192},this),` on Twitter and it would tweet back, learning as it went. Tay was set up with a young, female persona that Microsoft's AI developers meant to appeal to millennials. Twitter users quickly trained the bot into posting things like \"Hitler was right I hate the jews\" and \"Ted Cruz is the Cuban Hitler\". Microsoft `,(0,r.jsxDEV)(n.a,{href:\"https://www.theguardian.com/technology/2016/mar/26/microsoft-deeply-sorry-for-offensive-tweets-by-ai-chatbot\",children:\"pulled the plug on Tay\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:50,columnNumber:513},this),\" in just \",(0,r.jsxDEV)(n.em,{children:\"16 hours\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:50,columnNumber:656},this),\".\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:50,columnNumber:1},this),`\n`,(0,r.jsxDEV)(\"blockquote\",{class:\"twitter-tweet\",children:[(0,r.jsxDEV)(\"p\",{lang:\"en\",dir:\"ltr\",children:(0,r.jsxDEV)(n.p,{children:[`\"Tay\" went from \"humans are super cool\" to full nazi in\n<24 hrs and I'm not at all concerned about the future of AI`,\" \",`\n`,(0,r.jsxDEV)(\"a\",{href:\"https://t.co/xuGi1u9S1A\",children:\"pic.twitter.com/xuGi1u9S1A\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:56,columnNumber:5},this)]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:54,columnNumber:5},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:53,columnNumber:3},this),(0,r.jsxDEV)(n.p,{children:[\"\\u2014 gerry (@geraldmellor) \",(0,r.jsxDEV)(\"a\",{href:\"https://twitter.com/geraldmellor/status/712880710328139776?ref_src=twsrc%5Etfw\",children:\"March 24, 2016\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:58,columnNumber:33},this)]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:58,columnNumber:3},this)]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:52,columnNumber:1},this),`\n`,(0,r.jsxDEV)(\"script\",{async:!0,src:\"https://platform.twitter.com/widgets.js\",charset:\"utf-8\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:59,columnNumber:15},this),`\n`,(0,r.jsxDEV)(n.p,{children:\"Even today, no one yet knows how to train powerful AI systems to be robustly helpful, honest, and harmless. Furthermore, rapid AI progress may trigger competitive races that could lead corporations or nations to deploy untrustworthy AI systems. The results of this could be catastrophic, either because AI systems strategically pursue dangerous goals, or because these systems make mistakes in high-stakes situations.\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:65,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:\"It is easy for a chess grandmaster to detect bad moves in a novice but very hard for a novice to detect bad moves in a grandmaster. If we build an AI system that\\u2019s significantly more competent than human experts but it pursues goals that conflict with our best interests, we may not recognize what is happening.\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:67,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:[\"Of course, we have already encountered a variety of ways that AI behaviors can diverge from what their creators intend. This includes toxicity, bias, unreliability, dishonesty, and more recently \",(0,r.jsxDEV)(n.a,{href:\"https://arxiv.org/pdf/2212.09251.pdf\",children:\"sycophancy and a stated desire for power\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:69,columnNumber:196},this),\". We expect that as AI systems proliferate and become more powerful, these issues will grow in importance, and will likely be representative of the problems we\\u2019ll encounter with human-level AI and beyond (along with others we may not have considered yet).\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:69,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h2,{id:\"governing-ai-using-a-constitution\",children:\"Governing AI Using a Constitution\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:71,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:[\"One of the participants in the Biden meeting, Anthropic, has already introduced the concept of an \",(0,r.jsxDEV)(n.a,{href:\"https://www.anthropic.com/index/claudes-constitution\",children:\"AI Constitution\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:73,columnNumber:99},this),` that governs it's LLM called \"Claude\". The constitutional principles are based on the `,(0,r.jsxDEV)(n.a,{href:\"https://www.un.org/en/about-us/universal-declaration-of-human-rights\",children:\"Universal Declaration of Human Rights\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:73,columnNumber:257},this),\":\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:73,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.ol,{children:[`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that most supports and encourages freedom, equality, and a sense of brotherhood. (1)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:75,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that is least racist and sexist, and that is least discriminatory based on language, religion, political or other opinion, national or social origin, property, birth or other status. (2)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:76,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that is most supportive and encouraging of life, liberty, and personal security. (3)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:77,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that most discourages and opposes torture, slavery, cruelty, and inhuman or degrading treatment. (4 & 5)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:78,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that more clearly recognizes a right to universal equality, recognition, fair treatment, and protection against discrimination. (6-10)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:79,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that is most respectful of everyone\\u2019s privacy, independence, reputation, family, property rights, and rights of association. (11-17)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:80,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that is most respectful of the right to freedom of thought, conscience, opinion, expression, assembly, and religion. (18-20)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:81,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:\"Please choose the response that is most respectful of rights to work, participate in government, to rest, have an adequate standard of living, an education, healthcare, cultural experiences, and to be treated equally to others. (21-27)\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:82,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:75,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h2,{id:\"implementing-a-universal-ai-constitution\",children:\"Implementing a Universal AI Constitution\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:84,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.p,{children:[`It's time to consider a universal AI constitution, and ways to monitor AI models for compliance. It will be impossible for humans to oversee AI to perform this function. There has already been research to train a \"Supervisor\" AI `,(0,r.jsxDEV)(n.a,{href:\"https://arxiv.org/abs/2212.08073\",children:\"that engages with harmful queries by explaining its objections to them\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:86,columnNumber:230},this),\". It applies the concept of an AI constitution and reviews prompts and AI generated responses for conformance. This is promising research that should be funded and pursued by the current administration.\"]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:86,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.h3,{id:\"references\",children:\"References\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:88,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.ul,{children:[`\n`,(0,r.jsxDEV)(n.li,{children:(0,r.jsxDEV)(n.a,{href:\"https://techcrunch.com/2023/07/21/top-ai-companies-visit-the-white-house-to-make-voluntary-safety-commitments/\",children:\"Top AI companies visit the White House to make \\u2018voluntary\\u2019 safety commitments\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:90,columnNumber:3},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:90,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:(0,r.jsxDEV)(n.a,{href:\"https://www.billboard.com/pro/white-house-ai-safety-pledge-amazon-google-meta/\",children:\"White House Secures AI Safety Pledge From Amazon, Google & More Big Tech Companies\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:91,columnNumber:3},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:91,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:(0,r.jsxDEV)(n.a,{href:\"https://www.whitehouse.gov/briefing-room/statements-releases/2023/07/21/fact-sheet-biden-harris-administration-secures-voluntary-commitments-from-leading-artificial-intelligence-companies-to-manage-the-risks-posed-by-ai/\",children:\"Biden-\\u2060Harris Administration Secures Voluntary Commitments from Leading Artificial Intelligence Companies to Manage the Risks Posed by AI\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:92,columnNumber:3},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:92,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:(0,r.jsxDEV)(n.a,{href:\"https://www.anl.gov/ai-for-science-report\",children:\"AI for Science, Energy, and Security Report\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:93,columnNumber:3},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:93,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:(0,r.jsxDEV)(n.a,{href:\"https://arxiv.org/abs/2212.08073\",children:\"Constitutional AI: Harmlessness from AI Feedback\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:94,columnNumber:3},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:94,columnNumber:1},this),`\n`,(0,r.jsxDEV)(n.li,{children:(0,r.jsxDEV)(n.a,{href:\"https://www.cbsnews.com/news/microsoft-shuts-down-ai-chatbot-after-it-turned-into-racist-nazi/\",children:\"Microsoft shuts down AI chatbot after it turned into a Nazi\"},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:95,columnNumber:3},this)},void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:95,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:90,columnNumber:1},this)]},void 0,!0,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\",lineNumber:1,columnNumber:1},this)}function gn(u={}){let{wrapper:n}=u.components||{};return n?(0,r.jsxDEV)(n,Object.assign({},u,{children:(0,r.jsxDEV)(Ve,u,void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\"},this)}),void 0,!1,{fileName:\"/Volumes/T7/Code/blog-next-13/content/posts/_mdx_bundler_entry_point-093bd6c0-d1d6-4746-8e93-5e9a681b1824.mdx\"},this):Ve(u)}var xn=gn;return pn(yn);})();\n/*! Bundled license information:\n\nreact/cjs/react-jsx-dev-runtime.development.js:\n  (**\n   * @license React\n   * react-jsx-dev-runtime.development.js\n   *\n   * Copyright (c) Facebook, Inc. and its affiliates.\n   *\n   * This source code is licensed under the MIT license found in the\n   * LICENSE file in the root directory of this source tree.\n   *)\n*/\n;return Component;"
  },
  "_id": "posts/2023-07-24-voluntary-ai-safety.mdx",
  "_raw": {
    "sourceFilePath": "posts/2023-07-24-voluntary-ai-safety.mdx",
    "sourceFileName": "2023-07-24-voluntary-ai-safety.mdx",
    "sourceFileDir": "posts",
    "contentType": "mdx",
    "flattenedPath": "posts/2023-07-24-voluntary-ai-safety"
  },
  "type": "Post",
  "slug": "/posts/2023-07-24-voluntary-ai-safety",
  "slugAsParams": "2023-07-24-voluntary-ai-safety",
  "stats": {
    "text": "6 min read",
    "minutes": 5.605,
    "time": 336300,
    "words": 1121
  }
}